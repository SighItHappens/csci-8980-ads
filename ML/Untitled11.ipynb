{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXZh_RdTsBD"
      },
      "source": [
        "!mkdir /content/drive/My\\ Drive/Distributed/\n",
        "\n",
        "%cd /content/drive/My\\ Drive/Distributed/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiuxLarMREjt"
      },
      "source": [
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure \n",
        "import time\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import deque\n",
        "from collections import defaultdict\n",
        "import tqdm\n",
        "import sys\n",
        "import sys\n",
        "import random\n",
        "from collections import Counter, deque, defaultdict\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JprRbyF3vPyQ"
      },
      "source": [
        "maxpos = 1000000000000\n",
        "\n",
        "num_params = 3\n",
        "\n",
        "cache_size = 100 # default cache size\n",
        "sampling_freq = cache_size # number of samples skipped\n",
        "eviction = int(0.7 * cache_size)  \n",
        "\n",
        "\n",
        "lruCorrect = 0\n",
        "lruIncorrect = 0\n",
        "\n",
        "lfuCorrect = 0\n",
        "lfuIncorrect = 0\n",
        "\n",
        "\n",
        "X = np.array([], dtype=np.int64).reshape(0,num_params)\n",
        "Y = np.array([], dtype=np.int64).reshape(0,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUiTEODptkP0"
      },
      "source": [
        "def lruPredict(C,LRUQ,Y_OPT):\n",
        "    global lruCorrect, lruIncorrect\n",
        "    Y_current = []\n",
        "    KV = defaultdict(int)\n",
        "    for i in range(len(LRUQ)):\n",
        "        KV[LRUQ[i]] = len(LRUQ) - i\n",
        "    KV_sorted = Counter(KV)\n",
        "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
        "    for e in C:\n",
        "        if e in evict_dict:\n",
        "            Y_current.append(1)\n",
        "        else:\n",
        "            Y_current.append(0)\n",
        "    for i in range(len(Y_current)):\n",
        "        if Y_current[i] is Y_OPT[i]:\n",
        "            lruCorrect+=1\n",
        "        else:\n",
        "            lruIncorrect+=1\n",
        "    return Y_current\n",
        "\n",
        "# returns sequence of blocks in prioirty order\n",
        "\n",
        "def Y_getBlockSeq(Y_pred_prob):\n",
        "    x = []\n",
        "    for i in range(len(Y_pred_prob)):\n",
        "        x.append(Y_pred_prob[i][0])\n",
        "    x = np.array(x)\n",
        "    idx = np.argsort(x)\n",
        "    idx = idx[:eviction]\n",
        "    return idx\n",
        "\n",
        "\n",
        "def Y_getMinPredict(Y_pred_prob):\n",
        "    x = []\n",
        "    for i in range(len(Y_pred_prob)):\n",
        "        x.append(Y_pred_prob[i][0])\n",
        "    x = np.array(x)\n",
        "    idx = np.argpartition(x, eviction)\n",
        "    \n",
        "    Y_pred = np.zeros(len(Y_pred_prob), dtype=int)\n",
        "    for i in range(eviction):\n",
        "        Y_pred[idx[i]] = 1\n",
        "    assert(Counter(Y_pred)[1] == eviction)\n",
        "    return Y_pred\n",
        "\n",
        "\n",
        "def lfuPredict(C,LFUDict,Y_OPT):\n",
        "    global lfuCorrect, lfuIncorrect\n",
        "    Y_current = []\n",
        "    KV = defaultdict()\n",
        "    for e in C:\n",
        "        KV[e] = LFUDict[e]\n",
        "    KV_sorted = Counter(KV)\n",
        "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
        "    for e in C:\n",
        "        if e in evict_dict:\n",
        "            Y_current.append(1)\n",
        "        else:\n",
        "            Y_current.append(0)\n",
        "    for i in range(len(Y_current)):\n",
        "        if Y_current[i] is Y_OPT[i]:\n",
        "            lfuCorrect+=1\n",
        "        else:\n",
        "            lfuIncorrect+=1\n",
        "    return Y_current\n",
        "\n",
        "# return \"eviction\" blocks that are being accessed furthest\n",
        "# from the cache that was sent to us.\n",
        "\n",
        "def getY(C,D):\n",
        "    assert(len(C) == len(D))\n",
        "    Y_current = []\n",
        "    KV_sorted = Counter(D)\n",
        "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
        "    assert(len(evict_dict) == eviction)\n",
        "    all_vals = evict_dict.values()\n",
        "    for e in C:\n",
        "        if e in evict_dict.values():\n",
        "            Y_current.append(1)\n",
        "        else:\n",
        "            Y_current.append(0)\n",
        "    #print (Y_current.count(1))\n",
        "    assert(Y_current.count(1) == eviction)\n",
        "    assert((set(all_vals)).issubset(set(C)))\n",
        "    return Y_current\n",
        "\n",
        "def getLFURow(LFUDict, C):\n",
        "    x_lfurow = []\n",
        "    for e in C:\n",
        "        x_lfurow.append(LFUDict[e])\n",
        "    norm = x_lfurow / np.linalg.norm(x_lfurow)\n",
        "    return norm\n",
        "    \n",
        "def getLRURow(LRUQ, C):\n",
        "    x_lrurow = []\n",
        "    KV = defaultdict(int)\n",
        "    for i in range(len(LRUQ)):\n",
        "        KV[LRUQ[i]] = i\n",
        "    for e in C:\n",
        "        x_lrurow.append(KV[e])\n",
        "    norm = x_lrurow / np.linalg.norm(x_lrurow)\n",
        "    return norm\n",
        "\n",
        "def normalize(feature, blocks):\n",
        "    x_feature = []\n",
        "    for i in range(len(blocks)):\n",
        "        x_feature.append(feature[blocks[i]])\n",
        "    return x_feature / np.linalg.norm(x_feature)\n",
        "\n",
        "def getX(LRUQ, LFUDict, C):\n",
        "#def getX(LRUQ, LFUDict, C, CacheTS, CachePID):   \n",
        "    X_lfurow = getLFURow(LFUDict, C)\n",
        "    X_lrurow = getLRURow(LRUQ, C)\n",
        "    X_bno    = C / np.linalg.norm(C)\n",
        "#     X_ts     = normalize(CacheTS, C)\n",
        "#     X_pid    = normalize(CachePID, C)\n",
        "    return (np.column_stack((X_lfurow, X_lrurow, X_bno)))\n",
        "    \n",
        "    \n",
        "def populateData(LFUDict, LRUQ, C, D):\n",
        "#def populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID):\n",
        "    global X,Y\n",
        "    C = list(C)\n",
        "    Y_current = getY(C, D)\n",
        "    #X_current = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
        "    X_current = getX(LRUQ, LFUDict, C)\n",
        "\n",
        "    Y = np.append(Y, Y_current)\n",
        "    X = np.concatenate((X,X_current))\n",
        "    assert(Y_current.count(1) == eviction)\n",
        "    return Y_current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bADQ6bNtpU7"
      },
      "source": [
        "def LFU(blocktrace, frame):\n",
        "    \n",
        "    cache = set()\n",
        "    cache_frequency = defaultdict(int)\n",
        "    frequency = defaultdict(int)\n",
        "    \n",
        "    hit, miss = 0, 0\n",
        "    \n",
        "    for block in tqdm.tqdm(blocktrace, leave=False):\n",
        "        frequency[block] += 1\n",
        "        \n",
        "        if block in cache:\n",
        "            hit += 1\n",
        "            cache_frequency[block] += 1\n",
        "        \n",
        "        elif len(cache) < frame:\n",
        "            cache.add(block)\n",
        "            cache_frequency[block] += 1\n",
        "            miss += 1\n",
        "\n",
        "        else:\n",
        "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
        "            cache_frequency.pop(e)\n",
        "            cache.remove(e)\n",
        "            cache.add(block)\n",
        "            cache_frequency[block] = frequency[block]\n",
        "            miss += 1\n",
        "    \n",
        "    hitrate = hit / ( hit + miss )\n",
        "    return hitrate"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRPOCOjNtp67"
      },
      "source": [
        "def LRU(blocktrace, frame):\n",
        "    \n",
        "    cache = set()\n",
        "    recency = deque()\n",
        "    hit, miss = 0, 0\n",
        "    \n",
        "    for block in tqdm.tqdm(blocktrace, leave=False):\n",
        "        \n",
        "        if block in cache:\n",
        "            recency.remove(block)\n",
        "            recency.append(block)\n",
        "            hit += 1\n",
        "            \n",
        "        elif len(cache) < frame:\n",
        "            cache.add(block)\n",
        "            recency.append(block)\n",
        "            miss += 1\n",
        "            \n",
        "        else:\n",
        "            cache.remove(recency[0])\n",
        "            recency.popleft()\n",
        "            cache.add(block)\n",
        "            recency.append(block)\n",
        "            miss += 1\n",
        "    \n",
        "    hitrate = hit / (hit + miss)\n",
        "    return hitrate"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awxjzO7vtywl"
      },
      "source": [
        "def belady_opt(blocktrace, frame):\n",
        "    global maxpos\n",
        "    \n",
        "    OPT = defaultdict(deque)\n",
        "    D = defaultdict(int)\n",
        "    LFUDict = defaultdict(int)\n",
        "    LRUQ = []\n",
        "    #CacheTS = defaultdict(int)\n",
        "    #CachePID = defaultdict(int)\n",
        "\n",
        "    for i, block in enumerate(tqdm.tqdm(blocktrace, desc=\"OPT: building index\")):\n",
        "        OPT[block].append(i)\n",
        "\n",
        "    hit, miss = 0, 0\n",
        "\n",
        "    C = []\n",
        "    #count=0\n",
        "    #seq_number = 0\n",
        "    for seq_number, block in enumerate(tqdm.tqdm(blocktrace, desc=\"OPT\")):\n",
        "#    for block in blocktrace: \n",
        "        LFUDict[block] +=1\n",
        "\n",
        "        if len(OPT[block]) is not 0 and OPT[block][0] == seq_number:\n",
        "            OPT[block].popleft()\n",
        "        #CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
        "        #CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
        "        if block in C:\n",
        "            hit+=1\n",
        "            LRUQ.remove(block)\n",
        "            LRUQ.append(block)\n",
        "            assert( seq_number in D)\n",
        "            del D[seq_number]\n",
        "            if len(OPT[block]) is not 0:\n",
        "                D[OPT[block][0]] = block\n",
        "                OPT[block].popleft()\n",
        "            else:\n",
        "                D[maxpos] = block\n",
        "                maxpos -= 1\n",
        "        else:\n",
        "            miss+=1\n",
        "            if len(C) == frame:\n",
        "                assert(len(D) == frame)\n",
        "                evictpos = max(D)\n",
        "                \n",
        "                if (seq_number % sampling_freq +1 == sampling_freq):\n",
        "                    #Y_OPT = populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID)\n",
        "                    Y_OPT = populateData(LFUDict, LRUQ, C, D)\n",
        "                    lruPredict(C,LRUQ,Y_OPT)\n",
        "                    lfuPredict(C,LFUDict,Y_OPT)\n",
        "                \n",
        "                C[C.index(D[evictpos])] = block\n",
        "                LRUQ.remove(D[evictpos])\n",
        "                #del CacheTS [D[evictpos]]\n",
        "                #del CachePID [D[evictpos]]\n",
        "                del D[evictpos]\n",
        "            else:\n",
        "                C.append(block)\n",
        "                \n",
        "            if len(OPT[block]) is not 0:\n",
        "                D[OPT[block][0]] = block\n",
        "                OPT[block].popleft()\n",
        "            else:\n",
        "                D[maxpos] = block\n",
        "                maxpos -= 1\n",
        "            LRUQ.append(block)\n",
        "\n",
        "\n",
        "    hitrate = hit / (hit + miss)\n",
        "    #print(hitrate)\n",
        "    return hitrate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNQHi1OAt0Vy"
      },
      "source": [
        "datablk = \"cheetah.cs.fiu.edu-110108-113008.2.blkparse\"\n",
        "\n",
        "df100 = pd.read_csv(datablk, sep =' ')\n",
        "# print(df.head().T)\n",
        "df100 = df100.iloc[1:]\n",
        "df100.columns = ['timestamp','pid','pname','bno', 'bsize', 'op', 'dvmajor', 'dvminor', 'blockhash']\n",
        "#df100.columns = ['no']\n",
        "\n",
        "blktrace = df100['bno'].tolist()[:100000]\n",
        "blocktrace = np.array([int(x) for x in blktrace])\n",
        "\n",
        "#seq = df['no'].tolist()\n",
        "seq = list(range(0,len(blktrace),1))\n",
        "sequences = np.array([int(x) for x in seq])\n",
        "cache_size=100\n",
        "\n",
        "trainHitrate = belady_opt(blocktrace, cache_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx8u4H5d-ro1"
      },
      "source": [
        "print(trainHitrate)\n",
        "import pickle as P\n",
        "infile = open('final/t_blktrace','wb')\n",
        "P.dump(blocktrace, infile)\n",
        "infile.close()\n",
        "\n",
        "outfile = open('final/X_train', \"wb\")\n",
        "P.dump(X,outfile)\n",
        "outfile.close()\n",
        "\n",
        "outfile = open('final/Y_train', \"wb\")\n",
        "P.dump(Y,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyeyai4YAw6y"
      },
      "source": [
        "def hitRate(blocktrace, frame, model):\n",
        "    LFUDict = defaultdict(int)\n",
        "    LRUQ = []\n",
        "#     CacheTS = defaultdict(int)\n",
        "#     CachePID = defaultdict(int)\n",
        "\n",
        "    hit, miss = 0, 0\n",
        "\n",
        "    C = []\n",
        "    evictCacheIndex = np.array([])\n",
        "    #count=0\n",
        "    #seq_number = 0\n",
        "    for seq_number, block in enumerate(tqdm.tqdm(blocktrace, desc=\"OPT\")):\n",
        "        #print(len(evictCacheIndex))\n",
        "        LFUDict[block] +=1\n",
        "        #CacheTS[blocktrace[seq_number]] = timestamp[seq_number]\n",
        "        #CachePID[blocktrace[seq_number]] = pid[seq_number]\n",
        "        if block in C:\n",
        "            hit+=1\n",
        "#             if C.index(block) in evictCacheIndex:\n",
        "#                 np.delete(evictCacheIndex, C.index(block))\n",
        "                \n",
        "            LRUQ.remove(block)\n",
        "            LRUQ.append(block)\n",
        "        else:\n",
        "            evictPos = -1\n",
        "            miss+=1\n",
        "            if len(C) == frame:\n",
        "                if len(evictCacheIndex) == 0: # call eviction candidates\n",
        "                    X_test = getX(LRUQ, LFUDict, C)\n",
        "                    #X_test = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
        "\n",
        "                    Y_pred_prob = model.predict_proba(X_test)\n",
        "                    # index of cache blocks that should be removed\n",
        "                    evictCacheIndex = Y_getBlockSeq(Y_pred_prob)\n",
        "                    #return Y_pred_prob, evictCacheIndex\n",
        "                # evict from cache\n",
        "                evictPos = evictCacheIndex[0]\n",
        "                evictBlock = C[evictPos]\n",
        "                LRUQ.remove(evictBlock)\n",
        "                #del CacheTS [evictBlock]\n",
        "                #del CachePID [evictBlock]\n",
        "            if evictPos is -1:\n",
        "                C.append(block)\n",
        "            else:\n",
        "                C[evictPos] = block\n",
        "                evictCacheIndex = np.delete(evictCacheIndex, 0)\n",
        "            LRUQ.append(block)\n",
        "            #CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
        "            #CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
        "        #seq_number += 1\n",
        "\n",
        "    hitrate = hit / (hit + miss)\n",
        "    print(hitrate)\n",
        "    return hitrate"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps2T1fW5BGaJ",
        "outputId": "425aa3b9-4d36-4157-b7ff-973f450b0631"
      },
      "source": [
        "\n",
        "outfile = open('final/X_train', \"rb\")\n",
        "X = P.load(outfile)\n",
        "outfile.close()\n",
        "\n",
        "outfile = open('final/Y_train', \"rb\")\n",
        "Y = P.load(outfile)\n",
        "outfile.close()\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_train, X_test = train_test_split(X, test_size=0.30,random_state=None, shuffle=True)\n",
        "Y_train, Y_test = train_test_split(Y, test_size=0.30,random_state=None, shuffle=True)\n",
        "\n",
        "print(Y_test[:20])\n",
        "\n",
        "NN = MLPClassifier()\n",
        "NN.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "print(NN.score(X_train, Y_train))\n",
        "print(confusion_matrix(Y_test,NN.predict(X_test)))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(69300,)\n",
            "[1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1]\n",
            "0.7000721500721501\n",
            "[[    0  8915]\n",
            " [    0 20785]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_yj9Ad2DKE4",
        "outputId": "7243060f-4a83-47bb-9e63-f156d8d7d29a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "print(logreg.score(X_train, Y_train))\n",
        "print(confusion_matrix(Y_test,logreg.predict(X_test)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6982539682539682\n",
            "[[    0  8789]\n",
            " [    0 20911]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gah_GqdBBgI",
        "outputId": "6acda7c0-8723-47f6-b1be-f6da600ee864"
      },
      "source": [
        "testHitrate = belady_opt(blocktrace[:int(.3*len(blocktrace))], cache_size)\n",
        "print(testHitrate)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OPT: building index: 100%|██████████| 30000/30000 [00:00<00:00, 901051.37it/s]\n",
            "OPT: 100%|██████████| 30000/30000 [00:00<00:00, 33622.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVthnKsQD0v2",
        "outputId": "f548a2c0-ccaa-4e3f-c93e-3f37b9bf8a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hitRate(blocktrace[int(.7*len(blocktrace)):], cache_size, NN)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OPT: 100%|██████████| 30000/30000 [00:01<00:00, 29580.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvwui2q0EPWL",
        "outputId": "8a93f459-455d-486c-9a2f-5c5952a0b0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "LFU(blocktrace[int(.7*len(blocktrace)):], cache_size)\n",
        "LRU(blocktrace[int(.7*len(blocktrace)):], cache_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.012266666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_OBMfbaIaMg"
      },
      "source": [
        "hr_CNN = hitRate(blocktrace, CACHE_SIZE, model)\n",
        "print(LRU(blocktrace, CACHE_SIZE))\n",
        "print(LFU(blocktrace, CACHE_SIZE))#0.04229397072599403\n",
        "LeCar = LeCarLruLfu(cache_size=CACHE_SIZE) #0.04168193991750793\n",
        "print(LeCar.run_algorithm(blocktrace, timestamp))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}